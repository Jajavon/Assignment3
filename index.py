# Indexer
# Create an inverted index for the corpus with data structures designed by you.
# • Tokens: all alphanumeric sequences in the dataset.

# Stop words: do not use stopping while indexing, i.e. use all words, even the frequently occurring ones.
# • Stemming: use stemming for better textual matches. Suggestion: Porter stemming, but it is up to you to choose.
# • Important text: text in bold (b, strong), in headings (h1, h2, h3), and in titles should be treated as more important than the in other places.
# Verify which are the relevant HTML tags to select the important words.




def index(pages):
    """
    input: crawled pages
    Information Analyst. In this flavor there is some programming involved, but not much more
    advanced than what you already did so far. It is a mixture of a Text Processing project and
    stitching things together. You will use a small subset of crawled pages.
    :return:
    """

def main():
    print()

if __name__ == "__main__":
    main()